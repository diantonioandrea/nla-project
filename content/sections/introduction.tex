\subsection{Subspace Embeddings}

\begin{definition}[Subspace embedding] \label{def:embedding}
    Let $s, d, n \in \NaturalNumbers$ and consider $\Matrix{M} \in \RealMatrices{n}{d}$ such that \\ $\Range{\Matrix{M}} = L \subseteq \RealVectors{n}$. A matrix $\Matrix{S} \in \RealMatrices{s}{n}$ is called a subspace embedding for $L$ with distortion $\varepsilon \in \left(0, 1\right)$ if:
    \begin{align}
        \left( 1 - \varepsilon \right) \Norm{\Matrix{M} \Vector{y}}_2 \leq \Norm{\Matrix{S} \Matrix{M} \Vector{y}}_2 &\leq \left( 1 + \varepsilon \right) \Norm{\Matrix{M} \Vector{y}}_2 &\text{for all } \Vector{y} \in \RealVectors{d}. \label{eq:embedding}
    \end{align}
\end{definition}

Due to the fact that the subspace $L$ in \cref{def:embedding} is usually unknown, the subspace embedding $\Matrix{S}$ is constructed at random in order to achieve \cref{eq:embedding} with high probability.

\subsection{Sketching for Least-Squares Problems}

Subspace embeddings, as defined in \cref{def:embedding}, can be used to reduces the dimension of a least-squares problem.

\begin{Fact}[Sketching for least-squares problems] \label{fact:least_squares}
    Let $s, d, n \in \NaturalNumbers$, $\Matrix{M} \in \RealMatrices{n}{d}$, $\Vector{v} \in \RealVectors{n}$ and consider $\Matrix{S} \in \RealMatrices{s}{n}$ subspace embedding for $\Range{\Matrix{M}, \Vector{v}}$. By \cref{def:embedding}:
    \begin{align}
        \left( 1 - \varepsilon \right) \Norm{\Matrix{M} \Vector{y} - \Vector{v}}_2 \leq \Norm{\Matrix{S} \left( \Matrix{M} \Vector{y} - \Vector{v} \right)}_2 &\leq \left( 1 + \varepsilon \right) \Norm{\Matrix{M} \Vector{y} - \Vector{v}}_2 &\text{for all } \Vector{y} \in \RealVectors{d}. \label{eq:sketched_least_squares_1}
    \end{align}
    In particular, denote by $\Vector{y}_{\star}, \Vector{y}^{\star} \in \RealVectors{d}$ respectively the solutions to the least-squares problem and the sketched least-squares problem, then:
    \begin{align}
        \Norm{\Matrix{M} \Vector{y}_{\star} - \Vector{v}}_2 \leq \Norm{\Matrix{M} \Vector{y}^{\star} - \Vector{v}}_2 \leq \frac{1 + \varepsilon}{1 - \varepsilon} \Norm{\Matrix{M} \Vector{y}_{\star} - \Vector{v}}_2. \label{eq:sketched_least_squares_2}
    \end{align}
\end{Fact}

\subsection{\textit{GMRES}, Derivation and Analysis of the \textit{sGMRES}}

Let $n \in \NaturalNumbers$,  $\Matrix{A} \in \RealMatrices{n}{n}$ and $\Vector{b} \in \RealVectors{n}$, the goal is to find $\Vector{x} \in \RealVectors{n}$ such that:
\begin{align}
    \Matrix{A} \Vector{x} = \Vector{b}. \label{eq:system}
\end{align}

Consider $d \in \NaturalNumbers$ such that $d \ll n$ and fix $\Matrix{B} \in \RealMatrices{n}{d}$, called \textit{basis}\footnote{Refer to \cref{sseq:basis} for a possible construction.}, with the property that $\Range{\Matrix{B}}$ contains a good approximate solution of \cref{eq:system}, that is:
\begin{align}
    \Matrix{A} \Matrix{B} \Vector{y} &\approx \Vector{b} &\text{for some } \Vector{y} \in \RealVectors{d}. \label{eq:app_system}
\end{align}

For the \textit{GMRES} method, fix an initial guess $\Vector{x}_0 \in \RealVectors{n}$, which leads to an initial residual $\Vector{r}_0 = \Vector{b} - \Matrix{A} \Vector{x}_0$, and consider the affine family of solutions of the form:
\begin{align}
    \Vector{x} = \Vector{x}_0 + \Matrix{B} \Vector{y},
\end{align}
which leads to a residual $\Vector{r} = \Vector{b} - \Matrix{A} \Vector{x} = \Vector{r}_0 - \Matrix{A} \Matrix{B} \Vector{y}$. The goal is to find $\Vector{y} \in \RealVectors{d}$ such that:
\begin{align}
    \Vector{y} = \min_{\Vector{z} \in \RealVectors{d}} \Norm{\Vector{r}_0 - \Matrix{A} \Matrix{B} \Vector{z}}_2. \label{eq:min_problem}
\end{align}
Note that \cref{eq:min_problem} can be solved by the means of a QR factorization of the reduced matrix $\Matrix{A} \Matrix{B}$.

To derive the \textit{sGMRES}, sketch \cref{eq:min_problem} by fixing $s \in \NaturalNumbers$ and constructing a subspace embedding $\Matrix{S} \in \RealMatrices{s}{n}$ for $\Range{\Matrix{A} \Matrix{B}, \Vector{r}_0}$ with distortion $\varepsilon \in \left(0, 1\right)$, so that the sketched problem becomes:
\begin{align}
    \Vector{y} = \min_{\Vector{z} \in \RealVectors{d}} \Norm{ \Matrix{S} \left( \Vector{r}_0 - \Matrix{A} \Matrix{B} \Vector{z} \right)}_2. \label{eq:sketched_min_problem}
\end{align}

Denote, similarly as in \cref{fact:least_squares}, by $\Vector{y}_{\star}, \Vector{y}^{\star} \in \RealVectors{d}$ the solutions of \cref{eq:min_problem,eq:sketched_min_problem}. It follows by \cref{eq:sketched_least_squares_2} that:
\begin{align}
    \Norm{\Matrix{A} \Vector{x}_{\star} - \Vector{b}}_2 \leq \Norm{\Matrix{A} \Vector{x}^{\star} - \Vector{b}}_2 \leq \frac{1 + \varepsilon}{1 - \varepsilon} \Norm{\Matrix{A} \Vector{x}_{\star} - \Vector{b}}_2, \label{eq:sketched_gmres_estimate}
\end{align}
where:
\begin{align}
    \Vector{x}_{\star} &= \Vector{x}_0 + \Matrix{B} \Vector{y}_{\star}, \\
    \Vector{x}^{\star} &= \Vector{x}_0 + \Matrix{B} \Vector{y}^{\star}.
\end{align}

Simply put, \cref{eq:sketched_gmres_estimate} implies that \textit{sGMRES} produce an approximate solution to \cref{eq:system} with a small residual when \textit{GMRES} does.