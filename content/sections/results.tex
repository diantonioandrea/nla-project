\subsection{Implementation}

The algorithm is implemented in low-level \lstinline{C++23} using Neon\footnote{Disabled on non-supported architectures} intrinsics for SIMD operations and OpenMP for parallelization. The implementation is available on \href{https://github.com/diantonioandrea/NASS}{GitHub}.

By default, the algorithm employs the memory-priority approach discussed in \cref{sseq:basis}, which reduces memory overhead by storing only the necessary columns of $\Matrix{B}$.

\subsection{Test Configuration}

The algorithm is tested using the following matrices available on \href{https://sparse.tamu.edu}{SuiteSparse}:

\begin{description}
    \item[\href{https://sparse.tamu.edu/CEMW/t2em}{t2em}] A non-symmetric square matrix with $n \approx \num{9.2e5}$ and approximately $\num{4.5e6}$ non-zero entries, arising from an electromagnetics problem.
    \item[\href{https://sparse.tamu.edu/VLSI/stokes}{stokes}] A non-symmetric, ill-conditioned square matrix with $n \approx \num{1.1e7}$ and approximately $\num{3.5e8}$ non-zero entries, originating from a semiconductor process problem.
\end{description}

The right-hand side $\Vector{b} \in \RealVectors{n}$ is computed as $\Vector{b} = \Matrix{A} \Vector{g}$, where $\Vector{g} \in \RealVectors{n}$ is a random vector sampled from the standard normal distribution.

The tests are conducted on a machine equipped with an AMD Ryzen 7 3700X CPU and 64 GB of RAM.

\newpage
\subsection{Results}

As illustrated in \cref{fig:t2em}, the \textit{k-sGMRES} algorithm demonstrates similar behavior to \lstinline{MATLAB}'s \textit{GMRES} algorithm with respect to relative residuals, while significantly outperforming it in terms of computational time.

% Missing data for t2em, GMRES.
\begin{figure}[!ht]
    \begin{subfigure}[b]{0.49\textwidth}
        \begin{tikzpicture}[scale=.9]
            \begin{loglogaxis}[
                xlabel={Iterations $\left( d \right)$},
                xtick={100, 250, 500, 1000, 2500, 5000},
                xticklabels={100, 250, 500, 1000, 2500, 5000},
                ylabel={Residual $\left( \Norm{\Matrix{A} \Vector{x} - \Vector{b}}_2 / \Norm{\Vector{b}}_2 \right)$},
                grid=both,
                legend pos=south west
            ]
            \addplot[color=\accentcolor, mark=*] coordinates {(100,8.059e-06) (250,1.172e-06) (500,3.910e-07) (1000,4.823e-08) (2500,1.426e-12) (5000,4.667e-15)};
            \addplot[color=black, mark=*] coordinates {(100,4.50e-06) (250,2.9e-07) (500,2.8e-08) (1000,1.6e-09)};
            \legend{\textit{k-sGMRES} (\lstinline{C++23}),\textit{GMRES} (\lstinline{MATLAB})}
            \end{loglogaxis}
        \end{tikzpicture}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \begin{tikzpicture}[scale=.9]
            \begin{loglogaxis}[
                xlabel={Iterations $\left( d \right)$},
                xtick={100, 250, 500, 1000, 2500, 5000},
                xticklabels={100, 250, 500, 1000, 2500, 5000},
                ylabel={Time $\left[ \unit{ms} \right]$},
                grid=both,
                legend pos=south east
            ]
            \addplot[color=\accentcolor, mark=*] coordinates {(100,2996) (250,6753) (500,13202) (1000,28834) (2500,100100) (5000,285141)};
            \addplot[color=black, mark=*] coordinates {(100,9937) (250,54045) (500,209483) (1000,792628)};
            \legend{\textit{k-sGMRES} (\lstinline{C++23}),\textit{GMRES} (\lstinline{MATLAB})}
            \end{loglogaxis}
        \end{tikzpicture}
    \end{subfigure}
    \caption{Comparison of the performance of the \textit{k-sGMRES} algorithm with $k = 4$ against \lstinline{MATLAB}'s \textit{GMRES} algorithm for the \textbf{t2em} matrix, in terms of relative residual (left) and computation time (right).}
    \label{fig:t2em}
\end{figure}

Moreover, \cref{fig:stokes} demonstrates that the \textit{k-sGMRES} algorithm is capable of handling larger matrices, such as the \textbf{stokes} matrix. To improve convergence, preconditioning techniques can and should be applied.

\begin{figure}[!ht]
    \begin{subfigure}[b]{0.49\textwidth}
        \begin{tikzpicture}[scale=.9]
            \begin{loglogaxis}[
                xlabel={Iterations $\left( d \right)$},
                xtick={100, 250, 500, 1000, 2500, 5000},
                xticklabels={100, 250, 500, 1000, 2500, 5000},
                ylabel={Residual $\left( \Norm{\Matrix{A} \Vector{x} - \Vector{b}}_2 / \Norm{\Vector{b}}_2 \right)$},
                grid=both,
                legend pos=north east
            ]
            \addplot[color=\accentcolor, mark=*] coordinates {(100,1.037e-03) (250,3.628e-04) (500,1.236e-04) (1000,4.016e-05) (2500,1.131e-05) (5000,2.377e-06)};
            \legend{\textit{k-sGMRES} (\lstinline{C++23})}
            \end{loglogaxis}
        \end{tikzpicture}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \begin{tikzpicture}[scale=.9]
             \begin{loglogaxis}[
                    xlabel={Iterations $\left( d \right)$},
                    xtick={100, 250, 500, 1000, 2500, 5000},
                    xticklabels={100, 250, 500, 1000, 2500, 5000},
                    ylabel={Time $\left[ \unit{ms} \right]$},
                    grid=both,
                    legend pos=north west
                ]
                \addplot[color=\accentcolor, mark=*] coordinates {(100,113070) (250,281376) (500,568571)(1000,1147874) (2500,3030201) (5000,6211285)};
                \legend{\textit{k-sGMRES} (\lstinline{C++23})}
                \end{loglogaxis}       \end{tikzpicture}
    \end{subfigure}
    \caption{Evaluation of the performance of the \textit{k-sGMRES} algorithm with $k = 4$ for the \textbf{stokes} matrix, in terms of relative residual (left) and computation time (right).}
    \label{fig:stokes}
\end{figure}

The comparison with \lstinline{MATLAB}'s \textit{GMRES} is omitted in \cref{fig:stokes} due to the latter's failure to converge within a reasonable time frame.